import random as rd
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import warnings
import pydot
import keras
from IPython.display import SVG
from keras.optimizers import Adam
from keras.utils.vis_utils import model_to_dot
from keras.constraints import non_neg

MATRICE_NOTE = []


for j in range(50):
    L=[5 for k in range(75)]+ [1 for k in range(75)]
    M=[1 for k in range(75)]+[5 for k in range(75)]
    MATRICE_NOTE.append(L)
    MATRICE_NOTE.append(M)




##Construction de la matrice utile au dataframe Ã  partir de la matrice de note
utile = []
lignes=len(MATRICE_NOTE)
colonnes=len(MATRICE_NOTE[1])
for i in range(lignes):
    for j in range(colonnes):
        utile.append([i, j, MATRICE_NOTE[i][j]])
utile=np.array(utile)


dataset=pd.DataFrame(utile, columns=['user_id', 'item_id', 'rating'])





## ALGO DE RECOMMEND




dataset.user_id = dataset.user_id.astype('category').cat.codes.values
dataset.item_id = dataset.item_id.astype('category').cat.codes.values

from sklearn.model_selection import train_test_split
train, test = train_test_split(dataset, test_size=0.20)

n_users, n_plats = len(dataset.user_id.unique()), len(dataset.item_id.unique())
n_latent_factors = 15
n_latent_factors_user =5
n_latent_factors_plat = 5


plat_input = keras.layers.Input(shape=[1],name='Item')
plat_embedding = keras.layers.Embedding(n_plats + 1, n_latent_factors_plat, name='Plat-Embedding')(plat_input)
plat_vec = keras.layers.Flatten(name='FlattenPlats')(plat_embedding)
plat_vec = keras.layers.Dropout(0.2)(plat_vec)

user_input = keras.layers.Input(shape=[1],name='User')
user_embedding = keras.layers.Embedding(n_users + 1, n_latent_factors_user,name='User-Embedding')(user_input)
user_vec = keras.layers.Flatten(name='FlattenUsers')(user_embedding)


concat = keras.layers.dot([plat_vec, user_vec], axes=1, normalize=False)
#concat=keras.layers.concatenate([plat_vec, user_vec], 0)
concat_dropout = keras.layers.Dropout(0.2)(concat)


dense = keras.layers.Dense(200,name='FullyConnected')(concat)
#dropout_1 = keras.layers.Dropout(0.2,name='Dropout')(dense)

"""dense_2 = keras.layers.Dense(100,name='FullyConnected-1')(concat)
dropout_2 = keras.layers.Dropout(0.2,name='Dropout')(dense_2)

dense_3 = keras.layers.Dense(50,name='FullyConnected-2')(dense_2)
dropout_3 = keras.layers.Dropout(0.2,name='Dropout')(dense_3)

dense_4 = keras.layers.Dense(20,name='FullyConnected-3', activation='relu')(dense_3)"""

result = keras.layers.Dense(1, activation='relu',name='Activation')(dense)

adam = Adam(lr=0.01)

model = keras.Model([user_input, plat_input], result)
model.compile(optimizer=adam, loss= 'mean_squared_error')

history = model.fit([train.user_id, train.item_id], train.rating, epochs=50, verbose=0)

y_test = model.predict([test.user_id, test.item_id])
y_data = model.predict([dataset.user_id, dataset.item_id])


pd.Series(history.history['loss']).plot(logy=True)
plt.xlabel("Epoch")
plt.ylabel("Train Error")

y_hat = np.round(model.predict([test.user_id, test.item_id]),0)
y_true = test.rating
from sklearn.metrics import mean_absolute_error
mean_absolute_error(y_true, y_hat)
